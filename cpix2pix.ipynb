{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip install tensorboard\n",
    "# !pip install albumentations\n",
    "# !pip install matplotlib\n",
    "#!pip install torchsummary\n",
    "#!pip install streamlit\n",
    "#!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch .nn as nn \n",
    "import torch .optim as optim \n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader , Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from models import Dicriminator , Genrator , init_weights\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('fashion_data_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [A.Resize(width=256 , height=256),\n",
    "    A.Normalize(mean=[0.5 , 0.5 , 0.5] , std=[0.5 , 0.5 ,0.5], max_pixel_value=255.0),\n",
    "    ToTensorV2()\n",
    "    \n",
    "    ],\n",
    "    additional_targets={\"image1\":\"image\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self, data,transform ):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        input_path = self.data.iloc[index]['input_image']\n",
    "        output_path = self.data.iloc[index]['output_image']\n",
    "        label = self.data.iloc[index]['label']\n",
    "        label_maped = {'jeans': 0, 'suit': 1, 'jacket': 2, 't shirt': 3, 'hoodie': 4, 'trouser': 5}\n",
    "        label = label_maped[label]\n",
    "        label=torch.tensor(label , dtype=torch.long)\n",
    "\n",
    "        input_image = plt.imread(input_path)\n",
    "        output_image = plt.imread(output_path)\n",
    "\n",
    "        augmentation = self.transform(image=input_image , image1=output_image)\n",
    "        input_image , output_image = augmentation[\"image\"] , augmentation[\"image1\"]\n",
    "        return input_image , output_image , label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8\n",
    "lr = 2e-4\n",
    "z_dim = 100\n",
    "channels = 3\n",
    "filters = 64\n",
    "epochs = 1000 \n",
    "writer_input = SummaryWriter(f\"log/input\")\n",
    "writer_fake = SummaryWriter(f\"log/fake\")\n",
    "writer_real = SummaryWriter(f\"log/real\")\n",
    "num_label = 6\n",
    "l1_lambda =100\n",
    "img_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_file, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Genrator (channels ,num_label,img_size, filters).to(device)\n",
    "disc=Dicriminator(channels,num_label,img_size).to(device)\n",
    "init_weights(disc)\n",
    "init_weights(gen)\n",
    "opt_gen = optim.Adam(gen.parameters(),lr=lr ,betas=(0.5,0.999))\n",
    "opt_disc = optim.Adam(disc.parameters(),lr=lr ,betas=(0.5,0.999))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "l1_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = Mydata(data,transform)\n",
    "data_loder = DataLoader(my_data , batch_size=batch_size , shuffle=True , num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    \n",
    "    for batch_idx, (input_image , output_image , label) in enumerate (tqdm(data_loder , leave=True)):\n",
    "        input_image = input_image.to(device)\n",
    "        output_image = output_image.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        ## trian disc \n",
    "        fake = gen(input_image, label)\n",
    "        disc_real = disc(input_image , output_image,label)\n",
    "        disc_fake = disc(input_image , fake.detach(),label)\n",
    "        disc_real_loss = criterion(disc_real ,torch.ones_like(disc_real))\n",
    "        disc_fake_loss = criterion(disc_fake ,torch.zeros_like(disc_fake))\n",
    "        disc_loss = (disc_real_loss +disc_fake_loss)/2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        disc_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        ##trian generator\n",
    "        output = disc(input_image , fake,label)\n",
    "        fake_loss = criterion(output ,torch.ones_like(output))\n",
    "        l1 = l1_loss(fake , output_image)*l1_lambda\n",
    "        gen_loss = fake_loss+l1 \n",
    " \n",
    "        gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        \n",
    "    if epoch%50 ==0 :\n",
    "        with torch.no_grad():\n",
    "            fake = gen(input_image, label)\n",
    "            img_grid_real = torchvision.utils.make_grid(output_image[:4], normalize=True)\n",
    "            img_grid_fake = torchvision.utils.make_grid(fake[:4], normalize=True)\n",
    "            img_grid_input = torchvision.utils.make_grid(input_image[:4], normalize=True)\n",
    "            writer_real.add_image(\"Real\", img_grid_real ,global_step = epoch)\n",
    "            writer_fake.add_image(\"Fake\", img_grid_fake,global_step = epoch)\n",
    "            writer_input.add_image(\"Real\", img_grid_input ,global_step = epoch)\n",
    "            writer_input.add_image(\"Fake\", img_grid_input,global_step = epoch)\n",
    "            save_checkpoint(gen, opt_gen, filename=\"gen_checkpoint.pth.tar\")\n",
    "            save_checkpoint(disc, opt_disc, filename=\"disc_checkpoint.pth.tar\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCGAN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
